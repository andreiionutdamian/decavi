# FAQ



1.9.22. TODO: PoAI/Security: Can private entities such as banks migrate and use public nodes safely?

Yes. We will actively promote this.

1.9.23. Client/UI: How can I control what jobs and what is going on in my fleet of boxes?

While the distribution and execution of the jobs and the resulting PoAI is based on the underlying blockchain the actual control and supervision can be done in a centralized-like manner via the CAVI interface. The CAVI suite of apps allow both the configuration, direct and indirect management of each and all boxes while acting as nodes in the blockchain and review-ing the statuses of the jobs as well as generated rewards.

1.9.24. Authomony/DAO: What other uses has the coin?

One of the main purposes of the utility token is to fuel further research and development of the compute box-nodes, client CAVI nodes as well as other applications and APIs within the ecosystems. A clear direction of improvement will be the release of software boxes that can be deployed as software nodes on any hardware even if they do not have direct streams and enabled features and act just as remote job offloading nodes.

1.9.25. Authomony/DAO: How will the decentralized network and projects evolve?

The project roadmap contains clear plans of releasing a software only box-node that will enable any willing distributed network participants to deploy their own capabilities or just provide PoAI capabilities. This specific step in the project roadmap will enable a new perspective of decentralized AI application development allowing execution of various jobs: from simple pre-made AI models that can be easily configured by non data scientists for various purposes up to complex custom-made deep learning models created by AI teams and distributedly executed in the network. Here are a few examples: Passive Compute - User A: passive network maintainer: User A has a powerful computer and good net connection A downloads the node and registers the node in the grid A receives income as long as the node is online Analytics use-case provider- User B: small project developer - demand forecasting B downloads the node and registers B connects local database to node B configures (no data science skills) the forecasting ML engine B sends train and prediction jobs in network B pays gas fees much smaller than major Cloud apps require for this job Data provider - passive - User D1: small/medium user/maintainer: D1 uses the box (sw and/or hw) for direct benefits - e.g. detecting personnel that do not comply to safety and health regulations D1 consumes computer power at maximum of device capability thus does not generate compute in the grid D1 generates data based on the usage of the system - e.g. pictures of personnel that does not use safety gear and/or medical face mask D1 contributes to the network with the pictures allowing other similar use-cases to improve themselves and receives reward. The whole security and safety of the data is automatically handled as the actual end-user does not interact with the datasets OBS: basically this active participant is similar to the passive except the fact that it is willing to participate with their own data to the ecosystem improvement and uses the box for use-cases that can be employed by other passive/active participants. Data provided - active: User D2: small/medium user/maintainer: D2 can be a user that does not use the box-node and the ecosystem for own needs D2 is able to allocate time and use human power to annotate datasets using the provided box-node and client-node D2 must stake some of the own funds to guarantee the quality of the data. This way bad practices - labeling randomly the observation, etc - used in various systems (such as Mechanical Turk) are avoided D2 jobs are peer-evaluated by other participants or by automated scripts that are already pre-trained for the given task and can verify if the labeling is off/random. If job is approved the stake will be released to D2 together with the rewards for the job Enterprise provider - User C: large project developer - complex system C downloads the node and registers Using more advanced skills the user develops a series of features for end-customers (existing of future) on top of the node C pays starting jobs gas fees and the node starts C customers use the services either on monthly fees or on-demand C receives generate revenue (CAVI) similar to a classic business but without requiring: specialized growing hw infrastructure, cloud provider dependency, proprietary frameworks, much lower marketing and internationalization costs and barriers

1.9.26. Warranty/QoS: How about QoS and warranties when the Project will be fully decentralized?

As with other decentralized autonomous or semi-autonomous organizations and projects, the Project will require that all active participants in the network (except passive nodes) stake their participation according to the provided services. Staking means basically putting financial collateral when trying to provide services in the network. Using the previous example with the three different types of active participants in the network - the small analytics use-case provider, the data provider and the enterprise solution provider - each individual participant to the network will have to stake some of their own existing tokens in order to be able to apply for a job. In the unfortunate case of bad performance as well as in the more unfortunate event of bad behavior the staked funds will be permanently taken from the participant and other measures - such as temporary ban or permanent ban - could be issued. This approach will ensure that all participants take a portion of the risk - directly proportional to the use-case and job they are doing - and the end-beneficiaries are covered by some kind of insurance/warranty for the services they are receiving.

1.9.27. Aside from staking collateral, are there other methods of QA?

Aside from the collateral staking that network service providers have to set aside as guarantee for the quality of services rendered to the beneficiaries network participants, a peer-to-peer review system will ensure that a proposed service provider is also reviewed by already trusted network providers as well as beneficiaries in order to ensure feasibility of services, security of the approaches and other technical and usability aspects.

1.9.28. Blockchain: Difference between private box fleet vs public boxes?

As mentioned the system relies on two blockchains - a private one and a public one. The private one enables anti-tampering features for the boxes as well as job distribution and allows private and closed enterprises to deploy fleets of boxes and benefit from the full features. The public network enables distribution of jobs and the resulting PoAI and rewards at large scale via the NFT smart contracts and the utility token.

1.9.29. Network: How do you deal with low network bandwidths?

Low bandwidth or high latency is a real issue for a lot of projects that tackle areas such as IoT, AI and blockchain. Our PoAI based blockchain allows the distribution of the jobs depending on the peer-to-peer bandwidth capabilities as well as the latency. Aside from using optimized peer-to-peer bandwidth balancing the system employs AI-based encryption and compression methods ensuring that no large amounts of data are transferred unless explicitly required.

1.9.30. Security: Can you rig/hack the system?

One of the basic features of the 1st private blockchain is that it does not allow tampering with various aspects at the box-node level or at the CAVI client-node level. Each configuration update as well as each alert is recorded in the private distributed blockchain ledger rendering practically impossible the hacking of the data.

1.9.31. AI/Security: How secure is the PoAI?

The network of boxes, no matter if we are discussing a private fleet or the global public network, is secured via two different blockchains. Aside from this for training AI models or even inference jobs we are either using end-to-end encryption or Federated Learning methods such as homomorphic encryption that does not require the reconstruction of original data. All scenarios, use cases and each individual job has very strict approaches with respect to private and confidential data obfuscation. No personal data can be reconstructed or traced back to original observations. Basically in the case of distributed training using highly confidential data we have the following general steps that ensure no confidential data is distributed and no model intrinsic information can be used in order to decrypt or understand the data: The “client” participant box-node will both compress and encrypt without the possibility of reconstruction the data with a pre-trained generic private model. For this purpose a database of pre-trained domain specific model is available to provide specific deep encoder models that perform homomorphic encryption while dramatically reducing the dimensionality of required data. Example: a special safety detector might require a model being trained on images of cars that have to comply with specific regulations (such as having specific tire chains in winter time). In this case a distributor box-node will encode using domain encoder high-definition images that have more than 5MB of data with a minimum of \~0.3MB in JPEG format to a 0.002MB - that is just 2048 bytes from the initial size of more than 6,000,000 bytes. Each nearby participant box-node will receive a shard of the efficiently compressed and encrypted data and will train a “homomorphic model” directly on this data. Think of it as a “public model” than can work with public keys (and public data) without knowing the private information. Example continued from previous step: After each model receives their shard - a small piece of the homomorphically encoded and compressed data - the local public model will be optimized using both the labels (obfuscated as simple numbers) and the encrypted observations. All resulting “public models” will be combined in a “aggregated public model” that will be “plugged” in a private model thus creating the final working end-to-end model The whole ecosystem is written in Python and is fully available for auditing purposes.

1.9.32. AI: What is the difference between node jobs and behaviors?

Each box including the future software-only box is able to perform two different kinds of jobs, that is the normal job of running an AI model on a given set of observations and the more complex job of taking a model and further tuning and improving the model based on local or remote collected information. In both scenarios the box requires two things: the Deep Learning model and the data to be used with the model either for prediction/inference or for improvement of the model through training. As such there are several approaches for running the proposed scenarios such as: (i) improving a remote model with local data without sending data to another box-node; (ii) improving a remote node via remote data where the box-node that does the job receives both the data and the model; (iii) running inference or prediction jobs with local model on data received from remote nodes; (iv) inferring/predicting insights with remote models on remote data. With respect to the data or the models there are no restrictions on the application domain: a box that is currently enabled for multiple AI video security and safety features can receive jobs for predictive analytics such as time-series prediction and vice versa. Employing homomorphic encryption and other data and model security approaches can be done in any of the above scenarios.

1.9.33. AI: How does the system work in terms of Federated Learning?

The network and the overall ecosystem works with two types of nodes: the box-nodes for local and remote job processing as well as the CAVI client-nodes. In terms of scenarios the ecosystem can support both fully decentralized distributed Federated Learning jobs as well as central node based jobs where both a box-node or a CAVI client-node can act as a central aggregation node.

1.9.34. Smart Cities: how about them? The foundation of this project resides in the years of work and experience of our team in the areas of safety, security and predictive analytics based on AI. It is also a fact that we are adding blockchain technology and decentralization ecosystem to an already working environment based on embedded devices running AI/Deep Learning based algorithms. One of the main range of already existing features address safety and security scenarios based on CCTV video streams and more. In Smart City environments our project can achieve two different important objectives: AI use cases and citizen participation both financial and technologically. AI features include optimized and green deployment of a grid of AI powered devices that would enable features like road safety, children areas security and safety, traffic and network balancing forecasting. Citizen participation is probably an even more important aspect: allow Smart City citizens to participate in the distributed grid of AI devices and reward them in the decentralized financial ecosystem. In short the Project will allow the address the following Smart City aspects: Build-in safety and security capabilities, based on a track-record of past projects and experience in the field, will enable deploying a decentralized grid of blockchain secured box-nodes that will be able to acquire classic CCTV signals as well as process other sources of data for various use-cases. Crowd funding the Smart City deployment through citizen participation. The Project will allow citizens to acquire box-nodes and put them to work in the decentralized Smart City grid of box-nodes. Thus, each participant will be able to get rewards from the system and the municipality will be able to crowdsource the project. Basically each participating citizen will be a shareholder of the municipality’s project. Connect, re-invest, finance through the decentralized financial system. Connecting the municipality project to the grid as well as cooperating with other similar smart city projects through sharing of knowledge and methodology will reap decentralized distributed workload for the municipality. The municipality will be able to use the generated tokens to re-invest in extending their own system or in other projects or just use the extra generated revenues in deposits, staking for providing PoS collateral to protocol consensus validator nodes or other methods that will yield annual revenue such as providing liquidity to decentralized exchanges that offer CAVI token swapping.

1.9.35. Decentralization/DAO: What is the partner network?

API framework platforms, databases, management information systems and most complex systems and software platforms rely on implementation partners and the underlying distribution and deployment network. From the pre-blockchain era our system has been developed with distribution and implementation partnership flexible scaling in mind. Minimization of adaptation/integration efforts, configuration and deployment without the need of expensive know-how such as Data Science or Deep Learning, simplicity of workflows - all these have been on our product roadmaps . Nevertheless, the introduction of the blockchain based decentralized ecosystem has a new set of features and options in store for our partner. Critical aspects such as ownership, reliability or internationalization strategy now have a new perspective. With the maturation of the decentralized network partners will be able to rely on each other rather than rely solely on a central technology provider while working in an international business environment rather than a local or regional area.

1.9.36. Decentralization/DAO: More about decentralized governance? New projects, services or providers will be chosen, validated and guaranteed using the CAVI governance token staking. New network/community participants will be able to invest in tokens and stake their tokens in order to prove their commitment towards servicing existing end-users organizations or individuals within the system. Ecosystem modifications and updates will be possible based on the fact that the whole system will be open-source and any able, good willing participant can stake and propose their own modifications. Any kind of new endeavors that can be technologically implemented in the ecosystem will be possible such as “non-core” projects and services.

1.9.37. AI/Decentralization: How about non-core projects that can be implemented by network participants? While the core features of the box-nodes are in the area of AI based safety as well as predictive analytics there are other projects that can use (a) decentralized AI/ML/DL infrastructure for deployment, processing, learning, etc, (b) incentivization mechanics. One such relevant and important area is that of blockchain based games where the project team will be able to use the proposed infrastructure for decentralized backend ecosystem while focusing on front-end aspects. Moreso, we will be encouraging network partners to provide frameworks that will use the existing box-node backends and provide metaverse API where AI-based entities can grow and evolve in the decentralized network for box-nodes (though no Skynet allowed!).

The AI Society Game: A simple example of non-core new service/project within the ecosystem can be presented in the following steps. Note that this is just for example purposes and does not represent an actual step in our planned roadmap as the gaming industry is not in the focus of DeCAVI founders however other partners can pivot/use this idea. New network participant ACME Ltd. wants to launch a new AI-based game. In this game each consumer-user has one or more in-game avatars that are freely and un-scripted interacting and evolving - all based on AI training, reinforcement learning and a minimal set of “governance” rules. ACME Ltd. develops the UI front-end of the game (iOs and Android) while working with the DeCAVI framework and constructs the avatar-deployment system where each avatar is an independent model that “lives” in the DeCAVI ecosystem. Basically the avatar continuously trains itself and interacts with the ecosystem using network available compute power and “produces” tokens for its owner based on the user's help, investments, etc. User of ACME Ltd. pays for the game/NFT/service and receives a non-trainer (or pretrained) NFT avatar that will run in the DeCAVI network - data (model data) on blockchain while the avatar code (training and actions) will run transparently in the network of box-nodes. The user will be able to redeem the avatar produced tokens and further monetize them (such as passive investments) within the game or outside Solar Power Plant Predictive Balancing & Management: another example and potential solution, unrelated to previous gaming project example. In this example we have a project/service provider that aims at offering predictive analytics services for energy grid balancing. Although this example belongs to the core area of DeCAVI founders expertise (safety, predictive analytics, etc) it does not represent a planned step in the internal roadmap. Company SMART Ltd. aims at developing a solution that automatically balances multiple solar power provider energy distribution in various energy networks and end-consumers based on predictive analytics. SMART Ltd. develops a centralized user interface backend that allows solar power plant companies to bid for energy distribution. At the same time a multitude of AI agents are required to predict various aspects such as: (a) individual outputs of the energy provider companies related to global location, weather, etc (b) meta-consumer energy consumption based on location, etc. SMART Ltd. will use DeCAVI ecosystem to easily develop agent-models and deploy them in the DeCAVI network (meta-consumer: city, large company, energy retailer, etc) Each individual solar power provider will have their own set of models (comprising a so-called “plant-agent”) that will offer services for generation prediction, consumption prediction, fault prediction, etc while each group of consumers will be analyzed by another special set of models. The model data will be stored and secured in blockchain while the individual “plant-agents” will run in the decentralized network of box-nodes.

1.9.38. Environment: how about known environment issues usually associated with blockchain?

Our aim is to architect as well as produce and deploy low energy and low carbon footprint edge devices able to collaboratively process jobs that are usually requiring huge amounts of energy and carbon footprint. The collaborative processing is based on the blockchain ecosystem as well as…. Aside from this approach we also look forward to developing further eco-friendly initiatives that will offset the carbon footprint of minted NFTs (usually residing and delivered as ERC-20 or BEP-20 tokens). Carbon-offsetting will be achieved also through CSR activities such as “planting a tree for each box” - that is planting a tree minted security NFT. More information will be provided as we are working on further developing and searching for potential partnerships that will allow us to materialize these plans.

1.9.39. Investment: What are the financial investment options?

Together with the launching of the security smart contract NFTs and the utility token ICO, stacking and liquidity pool mechanisms will be offered for potentially interested investors. These classic electronic coin financial investment approaches will further promote and fuel the usage of the utility token. More information will be provided. While the main rewards generation system will be based on the PoAI consensus the CAVI token will run on ERC20/BEP20/… network based on PoS mechanics and thus allowing staking, liquidity pools and other digital DeFi options.

1.9.40. Founders: Who are the founders?

The founder information can be found [here](../team.md)

1.9.41. Learning, societal, charity & academic support & responsibility

We have multiple options and proposal for network and overall organization social responsibility and giving back to the community: Grants that will allow communities without financial resources to deploy safety systems with focus on: Junior research: College and similar establishments - Programs enabling students and even younger children to develop and experiment with the ecosystem, create their own applications, deploy them on main-net and monetize the proposed ideas Advanced research: University and CS departments in particular where grad students and their instructors and supervisors can engage in advanced projects that would benefit the whole network. Professional research: Research organizations Competitions and hackathons that will enable construction of new dApps in the ecosystem as well as creation of new teams and participants entities

1.9.42. Learning: Will there be casual workshops and learn-to-earn campaigns?

In order to support the growth of our community we will periodically and gradually deploy online workshops that will include small quizzes. Passing the quiz will activate a faucet mechanism and a small amount of CAVI tokens will be delivered to the participants.

1.9.43. Certification: Will there be advanced courses and certifications?

Our plans include the creation of our Academy that will allow partners and even individuals to attend advanced tracks for developing complex applications using our ecosystem. The tracks can also include certification exams that will confer the attendants proof of verified skills and knowledge.
